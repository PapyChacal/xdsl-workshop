{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a torch model in MLIR Syntax\n",
    "\n",
    "Those can already be generated by [Torch-MLIR](https://github.com/llvm/torch-mlir)!\n",
    "\n",
    "Let's just parse it and print it for now\n",
    "\n",
    "One can see that some tensor literals are only used in transpose operations. Let's optimize this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xdsl, riscemu\n",
    "from torchxdsl.dialect import *\n",
    "\n",
    "from xdsl.dialects.func import Func\n",
    "from xdsl.dialects.builtin import Builtin\n",
    "from xdsl.parser import Parser, Source\n",
    "\n",
    "from compiler import print_op\n",
    "from xdsl.ir import MLContext\n",
    "\n",
    "context = MLContext()\n",
    "context.register_dialect(Torch)\n",
    "context.register_dialect(Func)\n",
    "context.register_dialect(Builtin)\n",
    "\n",
    "with open('examples/alexnet.mlir')as f:\n",
    "    parser = Parser(context, f.read(), Source.MLIR, f.name)\n",
    "    module = parser.parse_module()\n",
    "\n",
    "print_op(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some things from the xdsl.pattern_rewriter module:\n",
    "from xdsl.pattern_rewriter import (GreedyRewritePatternApplier,\n",
    "                                   PatternRewriter, PatternRewriteWalker,\n",
    "                                   RewritePattern, op_type_rewrite_pattern)\n",
    "\n",
    "# Create our rewriter class:\n",
    "class TransposedLiteralOptimizer(RewritePattern):\n",
    "    \n",
    "    @op_type_rewrite_pattern\n",
    "    def match_and_rewrite(self, transpose: TransposeOp, rewriter: PatternRewriter):\n",
    "        \"\"\"\n",
    "        This method will be called on each TransposeOp in our Torch-xDSL module.\n",
    "        \"\"\"\n",
    "        # we iterate over all operands (arguments) of the add instruction\n",
    "        if isinstance(transpose.tensor.op, VTensorLitteralOp):\n",
    "            \n",
    "            transposed_literal = transpose.tensor.op.clone()\n",
    "\n",
    "            # this crashes after the xDSL update. Really we'd need to rewrite this, as\n",
    "            # this code doesn't quite follow recommended style. We'll fix it as we migrate\n",
    "            # it to the main xdsl repo\n",
    "\n",
    "\n",
    "            # t = transposed_literal.res.typ.dimensions.data[transpose.dim1.op.value.value.data]\n",
    "            # transposed_literal.res.typ.dimensions.data[transpose.dim1.op.value.value.data] = transposed_literal.res.typ.dimensions.data[transpose.dim2.op.value.value.data]\n",
    "            # transposed_literal.res.typ.dimensions.data[transpose.dim2.op.value.value.data] = t\n",
    "\n",
    "            # rewriter.replace_matched_op(transposed_literal)\n",
    "            # if len(transpose.tensor.uses) == 0:\n",
    "            #     rewriter.erase_op(transpose.tensor.op)\n",
    "            \n",
    "optimized_module = module.clone()\n",
    "PatternRewriteWalker(TransposedLiteralOptimizer()).rewrite_module(optimized_module)\n",
    "print_op(optimized_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
